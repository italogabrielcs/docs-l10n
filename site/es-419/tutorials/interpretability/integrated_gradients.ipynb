{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic4_occAAiAT"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ioaprt5q5US7"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPrjeJhFQBmu"
      },
      "source": [
        "# Gradientes integrados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKY4XMc9o8iB"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/interpretability/integrated_gradients\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a>\n",
        "</td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/interpretability/integrated_gradients.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver en GitHub</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/interpretability/integrated_gradients.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar notebook</a>\n",
        "</td>\n",
        "  <td>     <a href=\"https://tfhub.dev/google/imagenet/inception_v1/classification/4\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\">Ver modelo de TF Hub</a>\n",
        "</td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG17_Wp6ikKf"
      },
      "source": [
        "En este tutorial se demuestra cómo implementar **gradientes integrados (IG)**, una técnica de [inteligencia artificial explicable](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence) presentada en la publicación [Axiomatic Attribution for Deep Networks](https://arxiv.org/abs/1703.01365) (Atribución axiomática para redes profundas). Los gradientes integrados tienen como objetivo explicar la relación entre las predicciones de un modelo en lo que respecta a sus atributos. Tiene muchos usos, incluidos los de entender la importancia de los atributos, identificar la asimetría estadística de los datos (conocida también como \"data screw\") y la depuración del rendimiento del modelo.\n",
        "\n",
        "Los gradientes integrados se han vuelto una técnica de interpretabilidad muy popular gracias a su amplia aplicabilidad en cualquier modelo diferenciable (p. ej., en imágenes, textos o datos estructurados), a su fácil implementación, a las justificaciones teóricas y a la eficiencia computacional relativa a enfoques alternativos, que permiten escalar el modelo a redes grandes y trabajar espacios como imágenes.\n",
        "\n",
        "Con este tutorial se mostrará en detalle una implementación paso a paso de gradientes integrados para entender la importancia de los atributos de pixeles de un clasificador de imágenes. Como ejemplo, tome esta [imagen](https://commons.wikimedia.org/wiki/File:San_Francisco_fireboat_showing_off.jpg) de un barco contraincendios que despide chorros de agua. Seguramente, clasificaría esta imagen como barco contraincendios y destacaría los pixeles que forman el barco y los cañones hidrantes como importantes para la toma de decisiones. Su modelo también clasificará esta imagen como barco contraincendios más adelante, en este mismo tutorial. Sin embargo, ¿destaca los mismos pixeles como importantes cuando explica la decisión?\n",
        "\n",
        "En las imágenes que se encuentran a continuación, bajo el título \"IG Attribution Mask\" (Máscara de atribuciones de gradientes integrados) y \"Original + IG Mask Overlay\" (Original + Superposición de máscara de gradientes integrados) podrá ver que en su modelo se destacan (en violeta) los pixeles que comprenden a los cañones hidrantes del barco y a los chorros de agua como más importantes que el barco mismo para la decisión. ¿Cómo hará el modelo para lograr la generalización que lo lleve a nuevos barcos contraincendios? ¿Qué pasará entonces con los barcos contraincendios que no tengan chorros de agua? Siga leyendo para conocer más acerca de cómo funciona el gradiente integrado y cómo aplicar los gradientes integrados a los modelos para entender mejor la relación entre las predicciones de estos gradientes y los atributos subyacentes.\n",
        "\n",
        "![Imagen de salida 1](images/IG_fireboat.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppydw6ZbKzM1"
      },
      "source": [
        "## Configuración"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbUMIubipgg0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVVV4BGrABkA"
      },
      "source": [
        "### Descarga de un clasificador de imágenes previamente entrenado del repositorio TF-Hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kwwJ35xmtoK"
      },
      "source": [
        "El gradiente integrado se puede aplicar en cualquier modelo diferenciable. Para seguir con el mismo tenor de la publicación original, se usará una versión previamente entrenada del mismo modelo, Inception V1, que descargará del repositorio [TensorFlow Hub](https://tfhub.dev/google/imagenet/inception_v1/classification/4)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14APZcfHolKj"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\n",
        "        name='inception_v1',\n",
        "        handle='https://tfhub.dev/google/imagenet/inception_v1/classification/4',\n",
        "        trainable=False),\n",
        "])\n",
        "model.build([None, 224, 224, 3])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjLRn2e5xFOb"
      },
      "source": [
        "En la página del módulo, deberá tener en cuenta lo siguiente sobre Inception V1:\n",
        "\n",
        "Las **entradas**: la forma esperada de las entradas para el modelo es `(None, 224, 224, 3)`. Se trata de un tensor 4D denso de tipo d flotante 32 (dtype float32) y forma `(batch_size, height, width, RGB channels)` cuyos elementos son los valores de color RGB de los pixeles normalizados para el rango [0, 1]. El primer elemento es `None` para indicar que el modelo puede tomar cualquier tamaño de lote entero.\n",
        "\n",
        "Las **salidas**: un `tf.Tensor` de logits (funciones logísticas) en forma de `(batch_size, 1001)`. Cada una de las filas representa el puntaje predicho del modelo por cada una de las 1001 clases de ImageNet. Para el índice de clase predicho superior del modelo puede usar `tf.math.argmax(predictions, axis=-1)`. Además, también puede convertir la salida de la función logística del modelo a probabilidades pronosticadas en todas las clases con `tf.nn.softmax(predictions, axis=-1)` para cuantificar la incertidumbre del modelo y, a la vez, explorar clases predichas similares para la depuración."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huZnb_O0L9mw"
      },
      "outputs": [],
      "source": [
        "def load_imagenet_labels(file_path):\n",
        "  labels_file = tf.keras.utils.get_file('ImageNetLabels.txt', file_path)\n",
        "  with open(labels_file) as reader:\n",
        "    f = reader.read()\n",
        "    labels = f.splitlines()\n",
        "  return np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rtrl-u7T6NEk"
      },
      "outputs": [],
      "source": [
        "imagenet_labels = load_imagenet_labels('https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STpIJr1Z5r_u"
      },
      "source": [
        "### Carga y procesamiento previo de imágenes con `tf.image`\n",
        "\n",
        "Ilustrará los gradientes integrados con dos imágenes de [Wikimedia Commons](https://commons.wikimedia.org/wiki/Main_Page): un [barco contraincendios](https://commons.wikimedia.org/wiki/File:San_Francisco_fireboat_showing_off.jpg) y un [panda gigante](https://commons.wikimedia.org/wiki/File:Giant_Panda_2.JPG)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOb0Adq-rU5J"
      },
      "outputs": [],
      "source": [
        "def read_image(file_name):\n",
        "  image = tf.io.read_file(file_name)\n",
        "  image = tf.io.decode_jpeg(image, channels=3)\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  image = tf.image.resize_with_pad(image, target_height=224, target_width=224)\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_khLTN75CLMJ"
      },
      "outputs": [],
      "source": [
        "img_url = {\n",
        "    'Fireboat': 'http://storage.googleapis.com/download.tensorflow.org/example_images/San_Francisco_fireboat_showing_off.jpg',\n",
        "    'Giant Panda': 'http://storage.googleapis.com/download.tensorflow.org/example_images/Giant_Panda_2.jpeg',\n",
        "}\n",
        "\n",
        "img_paths = {name: tf.keras.utils.get_file(name, url) for (name, url) in img_url.items()}\n",
        "img_name_tensors = {name: read_image(img_path) for (name, img_path) in img_paths.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYIeu8rMLN-8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "for n, (name, img_tensors) in enumerate(img_name_tensors.items()):\n",
        "  ax = plt.subplot(1, 2, n+1)\n",
        "  ax.imshow(img_tensors)\n",
        "  ax.set_title(name)\n",
        "  ax.axis('off')\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvTYc8IZKbeO"
      },
      "source": [
        "### Clasificación de imágenes\n",
        "\n",
        "Comencemos con la clasificación de estas imágenes y mostremos las 3 predicciones más confiables. A continuación, hay una función de utilidad para extraer las etiquetas y las probabilidades predichas top k."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gsO7ILHZ0By"
      },
      "outputs": [],
      "source": [
        "def top_k_predictions(img, k=3):\n",
        "  image_batch = tf.expand_dims(img, 0)\n",
        "  predictions = model(image_batch)\n",
        "  probs = tf.nn.softmax(predictions, axis=-1)\n",
        "  top_probs, top_idxs = tf.math.top_k(input=probs, k=k)\n",
        "  top_labels = imagenet_labels[tuple(top_idxs)]\n",
        "  return top_labels, top_probs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l80a8N2vcIP-"
      },
      "outputs": [],
      "source": [
        "for (name, img_tensor) in img_name_tensors.items():\n",
        "  plt.imshow(img_tensor)\n",
        "  plt.title(name, fontweight='bold')\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  pred_label, pred_prob = top_k_predictions(img_tensor)\n",
        "  for label, prob in zip(pred_label, pred_prob):\n",
        "    print(f'{label}: {prob:0.1%}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-lH1N4timM2"
      },
      "source": [
        "## Cálculo de gradientes integrados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV7pfZHANaz1"
      },
      "source": [
        "El modelo, Inception V1, es una función aprendida que describe un mapeo entre el espacio de la función de entrada, los valores de los pixeles de la imagen y un espacio de salida definido por los valores probabilísticos de clase ImageNet entre 0 y 1. Los primeros métodos de interpretabilidad para redes neurales asignaban puntajes de importancia de atributos con gradientes, con lo que obtienes qué pixeles tienen el local más pronunciado en relación con las predicciones de su modelo en un punto dado junto con la función de predicción del modelo. Sin embargo, los gradientes solamente describen los cambios de *locales* en la función de predicción del modelo con respecto a los valores de pixeles y no describen la función de predicción del modelo entero. Dado que su modelo \"aprende\" completamente la relación entre el rango de un pixel individual y la clase ImageNet correcta, el gradiente para este pixel *saturará*, es decir, se volverá cada vez más pequeño hasta llegar a cero. Considere la función del modelo simple que se encuentra a continuación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AUkIUvpkaO8"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "  \"\"\"A simplified model function.\"\"\"\n",
        "  return tf.where(x < 0.8, x, 0.8)\n",
        "\n",
        "def interpolated_path(x):\n",
        "  \"\"\"A straight line path.\"\"\"\n",
        "  return tf.zeros_like(x)\n",
        "\n",
        "x = tf.linspace(start=0.0, stop=1.0, num=6)\n",
        "y = f(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMdAKooulVRE"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "fig = plt.figure(figsize=(12, 5))\n",
        "ax0 = fig.add_subplot(121)\n",
        "ax0.plot(x, f(x), marker='o')\n",
        "ax0.set_title('Gradients saturate over F(x)', fontweight='bold')\n",
        "ax0.text(0.2, 0.5, 'Gradients > 0 = \\n x is important')\n",
        "ax0.text(0.7, 0.85, 'Gradients = 0 \\n x not important')\n",
        "ax0.set_yticks(tf.range(0, 1.5, 0.5))\n",
        "ax0.set_xticks(tf.range(0, 1.5, 0.5))\n",
        "ax0.set_ylabel('F(x) - model true class predicted probability')\n",
        "ax0.set_xlabel('x - (pixel value)')\n",
        "\n",
        "ax1 = fig.add_subplot(122)\n",
        "ax1.plot(x, f(x), marker='o')\n",
        "ax1.plot(x, interpolated_path(x), marker='>')\n",
        "ax1.set_title('IG intuition', fontweight='bold')\n",
        "ax1.text(0.25, 0.1, 'Accumulate gradients along path')\n",
        "ax1.set_ylabel('F(x) - model true class predicted probability')\n",
        "ax1.set_xlabel('x - (pixel value)')\n",
        "ax1.set_yticks(tf.range(0, 1.5, 0.5))\n",
        "ax1.set_xticks(tf.range(0, 1.5, 0.5))\n",
        "ax1.annotate('Baseline', xy=(0.0, 0.0), xytext=(0.0, 0.2),\n",
        "             arrowprops=dict(facecolor='black', shrink=0.1))\n",
        "ax1.annotate('Input', xy=(1.0, 0.0), xytext=(0.95, 0.2),\n",
        "             arrowprops=dict(facecolor='black', shrink=0.1))\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LswhGFd0xZBr"
      },
      "source": [
        "- **Izquierda**: los gradientes de su modelo para el pixel `x` son positivos entre 0.0 y 0.8, pero van a 0.0 entre 0.8 y 1.0. El pixel `x` claramente tiene un impacto significativo en impulsar el modelo hacia una probabilidad prevista del 80% en la clase verdadera. <em data-md-type=\"emphasis\">¿Tiene sentido que la importancia del pixel `x` sea poca o discontinua?</em>\n",
        "\n",
        "- **Derecha**: la intuición detrás de IG consiste en acumular los gradientes locales de pixel `x` y atribuirles la importancia como un puntaje de cuánto suma o resta a la probabilidad de clase de salida general del modelo. Se puede descomponer y calcular IG en tres partes:\n",
        "\n",
        "    1. Interpolar pequeños pasos a lo largo de una línea recta en el espacio de atributos entre 0 (una línea de base o un punto de inicio) y 1 (valor de pixel de entrada)\n",
        "    2. Calcular los gradientes a cada paso entre las predicciones del modelo con respecto a cada uno de los pasos\n",
        "    3. Aproximar la integral entre la línea de base y la entrada mediante la acumulación (promedio acumulativo) de estos gradientes locales.\n",
        "\n",
        "Para reforzar esta intuición, realizará estas 3 partes mediante la aplicación de IG al ejemplo de la imagen del \"barco contraincendios\" que se encuentra a continuación. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28MU35BCLM-s"
      },
      "source": [
        "### Establecimiento de una línea de base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIPG5yYfkydQ"
      },
      "source": [
        "La línea de base es una imagen de entrada que se usa como punto de partida para calcular la importancia de los atributos. Intuitivamente, puede pensar que el rol explicativo de la línea de base es el de representar el impacto de la ausencia de cada pixel en la predicción del \"barco contraincendios\" para contrastarlo con el impacto de cada pixel en la predicción (del \"barco contraincendios\") cuando se encuentra presente en la imagen de entrada. Como resultado, la elección de la línea de base juega un rol central en la interpretación y visualización de la importancia de los atributos de los pixeles. Para más detalles sobre la selección de la línea de base, consulte la sección \"Próximos pasos\" al final de este tutorial. Aquí usará una imagen negra cuyos valores de pixeles son todos cero.\n",
        "\n",
        "Podría probar con otras opciones como con una imagen toda blanca o una imagen aleatoria que puede crear con `tf.random.uniform(shape=(224,224,3), minval=0.0, maxval=1.0)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxvpwGkj4G4J"
      },
      "outputs": [],
      "source": [
        "baseline = tf.zeros(shape=(224,224,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXRYwBWQS19B"
      },
      "outputs": [],
      "source": [
        "plt.imshow(baseline)\n",
        "plt.title(\"Baseline\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xphryu2mGAk8"
      },
      "source": [
        "### Desempaquetamiento de fórmulas en código"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QstMR0IcbfFA"
      },
      "source": [
        "La fórmula para gradientes integrados es la siguiente:\n",
        "\n",
        "$IntegratedGradients_{i}(x) ::= (x_{i} - x'{em0}{i})\\times\\int{/em0}{\\alpha=0}^1\\frac{\\partial F(x'+\\alpha \\times (x - x'))}{\\partial x_i}{d\\alpha}$\n",
        "\n",
        "donde:\n",
        "\n",
        "$_{i}$ = atributo<br> $x$ = entrada<br> $x'$ = línea de base<br> $\\alpha$ = constante de interpolación para perturbar atributos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7w8SD5YMqvi"
      },
      "source": [
        "En la práctica, el cálculo de una integral definida no siempre es numéricamente posible y puede tener un alto costo con respecto al cálculo, por lo tanto, calcule la siguiente aproximación numérica:\n",
        "\n",
        "$IntegratedGrads^{approx}{em0}{i}(x)::=(x{/em0}{i}-x'{em1}{i})\\times\\sum{/em1}{k=1}^{m}\\frac{\\partial F(x' + \\frac{k}{m}\\times(x - x'))}{\\partial x_{i}} \\times \\frac{1}{m}$\n",
        "\n",
        "donde:\n",
        "\n",
        "${em0}{i}$ = atributo (pixel individual)<br> $x$ = entrada (tensor de imagen)<br> $x'$ = línea de base (tensor de imagen)<br> $k$ = constante de perturbación de atributo escalada<br> $m$ = número de pasos en la aproximación de la suma de Riemann de la integral<br> $(x{/em0}{i}-x'_{i})$ = un término para la diferencia con respecto a la línea de base. Es necesario para escalar los gradientes integrados y para mantenerlos dentro de los términos de la imagen original. La ruta desde la imagen de base a la entrada se encuentra en espacio de pixeles. Como en los gradientes integrados lo que se hace es integrar en una línea recta (transformación lineal), termina siendo prácticamente equivalente al término integral de la derivada de la función de la imagen interpolada con respecto a $\\alpha$, con los pasos suficientes. La integral suma el gradiente de cada pixel multiplicado por el cambio del pixel a lo largo de la ruta. Es más simple implementar esta integración como pasos uniformes de una imagen a otra, sustituyendo $x := (x' + \\alpha(x-x'))$. Entonces, el cambio de variables da $dx = (x-x')d\\alpha$. El término $(x-x')$ es constante y se factoriza fuera de la integral."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aPG68RssS2h"
      },
      "source": [
        "### Interpolación de imágenes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPrldEYsIR4M"
      },
      "source": [
        "$IntegratedGrads^{approx}{em0}{i}(x)::=(x{/em0}{i}-x'{em1}{i})\\times\\sum{/em1}{k=1}^{m}\\frac{\\partial F(\\overbrace{x' + \\frac{k}{m}\\times(x - x')}^\\text{interpolate m images at k intervals})}{\\partial x_{i}} \\times \\frac{1}{m}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4r-ZrIIsdbI"
      },
      "source": [
        "Primero, generará una [interpolación lineal](https://en.wikipedia.org/wiki/Linear_interpolation) entre la línea de base y la imagen original. Puede pensar en la imágenes interpoladas como pequeños pasos en el espacio de atributos entre la línea de base y la entrada, representado por $\\alpha$ en la ecuación lineal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I42mBKXyjcIc"
      },
      "outputs": [],
      "source": [
        "m_steps=50\n",
        "alphas = tf.linspace(start=0.0, stop=1.0, num=m_steps+1) # Generate m_steps intervals for integral_approximation() below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SWLSFOHsbgh"
      },
      "outputs": [],
      "source": [
        "def interpolate_images(baseline,\n",
        "                       image,\n",
        "                       alphas):\n",
        "  alphas_x = alphas[:, tf.newaxis, tf.newaxis, tf.newaxis]\n",
        "  baseline_x = tf.expand_dims(baseline, axis=0)\n",
        "  input_x = tf.expand_dims(image, axis=0)\n",
        "  delta = input_x - baseline_x\n",
        "  images = baseline_x +  alphas_x * delta\n",
        "  return images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4zFzbUBj684"
      },
      "source": [
        "Usemos la función que figura arriba para generar imágenes interpoladas a lo largo de una ruta lineal a intervalos alfa entre una imagen de base negra y la imagen de ejemplo del \"barco contraincendios\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgVx8swDQtTl"
      },
      "outputs": [],
      "source": [
        "interpolated_images = interpolate_images(\n",
        "    baseline=baseline,\n",
        "    image=img_name_tensors['Fireboat'],\n",
        "    alphas=alphas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QABFsuCvkO1h"
      },
      "source": [
        "Observemos las imágenes interpoladas. Nota: otra forma de pensar la constante $\\alpha$ es considerando que aumente consistentemente la intensidad de cada imagen interpolada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tmBGdnHAupk"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(20, 20))\n",
        "\n",
        "i = 0\n",
        "for alpha, image in zip(alphas[0::10], interpolated_images[0::10]):\n",
        "  i += 1\n",
        "  plt.subplot(1, len(alphas[0::10]), i)\n",
        "  plt.title(f'alpha: {alpha:.1f}')\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.tight_layout();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7T0f1cqsaxA"
      },
      "source": [
        "### Cálculo de gradientes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tps0eWc0REqL"
      },
      "source": [
        "Ahora, echemos un vistazo a cómo se calculan los gradientes para medir la relación entre los cambios hechos a un atributo y los cambios en las predicciones del modelo. En el caso de las imágenes, el gradiente nos dice qué pixeles tienen mayor efecto en las probabilidades de clase predichas de los modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouuVIsdfgukW"
      },
      "source": [
        "$IntegratedGrads^{approx}{em0}{i}(x)::=(x{/em0}{i}-x'{em1}{i})\\times\\sum{/em1}{k=1}^{m}\\frac{\\overbrace{\\partial F(\\text{interpolated images})}^\\text{compute gradients}}{\\partial x_{i}} \\times \\frac{1}{m}$\n",
        "\n",
        "donde:<br> $F()$ = la función de predicción del modelo <br> $\\frac{\\partial{F}}{\\partial{x_i}}$ = gradiente (vector de derivadas parciales $\\partial$) de la función de predicción del modelo F relativa a cada atributo $x_i$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY_Ok3CoJW1W"
      },
      "source": [
        "TensorFlow facilita el cálculo de gradientes con [`tf.GradientTape`](https://www.tensorflow.org/api_docs/python/tf/GradientTape)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JW1O9qEsxZOP"
      },
      "outputs": [],
      "source": [
        "def compute_gradients(images, target_class_idx):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(images)\n",
        "    logits = model(images)\n",
        "    probs = tf.nn.softmax(logits, axis=-1)[:, target_class_idx]\n",
        "  return tape.gradient(probs, images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BfRuzx4-c87"
      },
      "source": [
        "Calculemos los gradientes de cada imagen junto con la ruta de interpolación, con respecto a la salida correcta. Recuerde que su modelo devuelve un `Tensor` con forma `(1, 1001)` con logits  que convierte a las probabilidades predichas para cada clase. Para la imagen, debe pasar el índice correcto de la clase de destino ImageNet a la función `compute_gradients`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHIR58rNJ3q_"
      },
      "outputs": [],
      "source": [
        "path_gradients = compute_gradients(\n",
        "    images=interpolated_images,\n",
        "    target_class_idx=555)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJodSbDUQ3T_"
      },
      "source": [
        "Tenga en cuenta la forma de salida de `(n_interpolated_images, img_height, img_width, RGB)`, que proporciona el gradiente para los pixeles de cada imagen a lo largo de la ruta de interpolación. Puede pensar en estos gradientes como que miden el cambio en las predicciones del modelo para cada pequeño paso en el espacio del atributo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2rpO2JTbQId"
      },
      "outputs": [],
      "source": [
        "print(path_gradients.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmaPpr5bUtbr"
      },
      "source": [
        "**Visualización de la saturación de gradiente**\n",
        "\n",
        "Recuerde que los gradientes que acaba de calcular arriba describen cambios *locales* en las probabilidades predictivas de su modelo de \"barco contraincendios\" y pueden *saturar*.\n",
        "\n",
        "Estos conceptos se visualizan con los gradientes que calculó arriba aplicados en los dos gráficos que se encuentran a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQWwcI0Wr0AX"
      },
      "outputs": [],
      "source": [
        "pred = model(interpolated_images)\n",
        "pred_proba = tf.nn.softmax(pred, axis=-1)[:, 555]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCH8sAf3TTJ2"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "plt.figure(figsize=(10, 4))\n",
        "ax1 = plt.subplot(1, 2, 1)\n",
        "ax1.plot(alphas, pred_proba)\n",
        "ax1.set_title('Target class predicted probability over alpha')\n",
        "ax1.set_ylabel('model p(target class)')\n",
        "ax1.set_xlabel('alpha')\n",
        "ax1.set_ylim([0, 1])\n",
        "\n",
        "ax2 = plt.subplot(1, 2, 2)\n",
        "# Average across interpolation steps\n",
        "average_grads = tf.reduce_mean(path_gradients, axis=[1, 2, 3])\n",
        "# Normalize gradients to 0 to 1 scale. E.g. (x - min(x))/(max(x)-min(x))\n",
        "average_grads_norm = (average_grads-tf.math.reduce_min(average_grads))/(tf.math.reduce_max(average_grads)-tf.reduce_min(average_grads))\n",
        "ax2.plot(alphas, average_grads_norm)\n",
        "ax2.set_title('Average pixel gradients (normalized) over alpha')\n",
        "ax2.set_ylabel('Average pixel gradients')\n",
        "ax2.set_xlabel('alpha')\n",
        "ax2.set_ylim([0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ntMpA87jNN6"
      },
      "source": [
        "- **Izquierda**: en este gráfico se muestra cómo varía la confianza de su modelo en la clase \"barco contraincendios\" a través de los alfas. Tenga en cuenta de qué modo los gradientes, o la pendiente de la línea, se aplana o satura entre 0.6 y 1.0 antes de instalarse en la probabilidad predictiva final para \"barco contraincendios\" de alrededor del 40%.\n",
        "\n",
        "- **Derecha**: en el gráfico de la derecha se muestran más directamente la magnitudes de los gradientes promedio sobre alfa. Tenga en cuenta el modo en que los valores se acercan abruptamente a cero e incluso caen brevemente por debajo de cero. De hecho, su modelo, de lo que más \"aprende\" es de los gradientes a valores inferiores de alfa antes de saturar. Intuitivamente, se puede pensar que el modelo ha aprendido los pixeles (p. ej., cuáles son los cañones hidrantes) para hacer las predicciones correctas, enviando estos gradientes de pixeles a cero. Pero todavía resulta bastante incierto y enfocado en pixeles espurios del puente o de los chorros de agua, a medida que los valores alfa se acercan a la imagen de entrada original.\n",
        "\n",
        "Para asegurarnos de que estos pixeles importantes de los cañones hidrantes se vean realmente reflejados como importantes en la predicción de \"barco contraincendios\", deberá continuar debajo para aprender cómo acumular estos gradientes para aproximar con exactitud de qué manera impacta cada pixel en la probabilidad predictiva del \"barco contraincendios\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQdACCM6sJdW"
      },
      "source": [
        "### Acumulación de gradientes (aproximación integral)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHopk9evmO5P"
      },
      "source": [
        "Hay muchas formas diferentes de abordar el cálculo de la aproximación numérica de una integral para gradientes integrados con diferentes compensaciones (tradeoffs) en cuanto a exactitud y convergencia a través de funciones variables. Una clase popular de métodos son las [sumas Riemann](https://en.wikipedia.org/wiki/Riemann_sum). A continuación, usará la regla trapezoidal (al final de este tutorial, puede hallar código adicional para explorar diferentes métodos de aproximación)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GshPZQgROs80"
      },
      "source": [
        "$IntegratedGrads^{approx}{em0}{i}(x)::=(x{/em0}{i}-x'{em1}{i})\\times \\overbrace{\\sum{/em1}{k=1}^{m}}^\\text{(Sumar m gradientes locales)}\\text{gradients(imágenes interpoladas)} \\times \\overbrace{\\frac{1}{m}}^\\text{Dividir por m pasos)}$\n",
        "\n",
        "A partir de la ecuación, puede ver que está sumando gradientes `m` y dividiendo por pasos `m`. Puede implementar dos operaciones juntas para la parte 3 como el <em data-md-type=\"emphasis\">promedio de los gradientes locales de las predicciones interpoladas de `m` y las imágenes de entrada</em>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cMVl-Grx3lp"
      },
      "outputs": [],
      "source": [
        "def integral_approximation(gradients):\n",
        "  # riemann_trapezoidal\n",
        "  grads = (gradients[:-1] + gradients[1:]) / tf.constant(2.0)\n",
        "  integrated_gradients = tf.math.reduce_mean(grads, axis=0)\n",
        "  return integrated_gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVQAHunkW79t"
      },
      "source": [
        "La función `integral_approximation` toma gradientes de la probabilidad predicha de la clase de destino con respecto a las imágenes interpoladas entre la línea de base y la original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeF01fydNq0I"
      },
      "outputs": [],
      "source": [
        "ig = integral_approximation(\n",
        "    gradients=path_gradients)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XVItLpurOAM"
      },
      "source": [
        "Puede confirmar que el promedio de los gradientes de `m` imágenes interpoladas devuelve un tensor de gradientes integrados con la misma forma de la imagen del \"Panda gigante\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1bP6l3ahfyn"
      },
      "outputs": [],
      "source": [
        "print(ig.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1ODXUevyGxL"
      },
      "source": [
        "### Unimos todo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcaTR-x8v1At"
      },
      "source": [
        "Ahora combinaremos las 3 partes generales anteriores juntas en una función `IntegratedGradients` y utilizaremos un decorador [@tf.function](https://www.tensorflow.org/guide/function) para compilarlas en un gráfico de TensorFlow invocable de alto rendimiento. Todo esto se implementa con los siguientes 5 pequeños pasos:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YdWHscoovhk"
      },
      "source": [
        "$IntegratedGrads^{approx}{em0}{i}(x)::=\\overbrace{(x{/em0}{i}-x'{em1}{i})}^\\text{5.}\\times \\overbrace{\\sum{/em1}{k=1}^{m}}^\\text{4.} \\frac{\\partial \\overbrace{F(\\overbrace{x' + \\overbrace{\\frac{k}{m}}^\\text{1.}\\times(x - x'))}^\\text{2.}}^\\text{3.}}{\\partial x_{i}} \\times \\overbrace{\\frac{1}{m}}^\\text{4.}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjdfjp_3pHiY"
      },
      "source": [
        "1. Generar alfas $\\alpha$\n",
        "\n",
        "2. Generar imágenes interpoladas = $(x' + \\frac{k}{m}\\times(x - x'))$\n",
        "\n",
        "3. Calcular los gradientes entre las predicciones de salida del modelo $F$ con respecto a los atributos de entrada= $\\frac{\\partial F(\\text{interpolated path inputs})}{\\partial x_{i}}$\n",
        "\n",
        "4. Lograr la aproximación integral a través del cálculo de promedios de gradientes = $\\sum_{k=1}^m \\text{gradients} \\times \\frac{1}{m}$\n",
        "\n",
        "5. Escalar los gradientes integrados con respecto a la imagen original = $(x_{i}-x'_{i}) \\times \\text{integrated gradients}$. Este paso es necesario para garantizar que los valores de atribución acumulados en múltiples imágenes interpoladas están en las mismas unidades y representan fielmente la importancia de los pixeles en la imagen original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_H3k9Eu7Rl5"
      },
      "outputs": [],
      "source": [
        "def integrated_gradients(baseline,\n",
        "                         image,\n",
        "                         target_class_idx,\n",
        "                         m_steps=50,\n",
        "                         batch_size=32):\n",
        "  # Generate alphas.\n",
        "  alphas = tf.linspace(start=0.0, stop=1.0, num=m_steps+1)\n",
        "\n",
        "  # Collect gradients.    \n",
        "  gradient_batches = []\n",
        "    \n",
        "  # Iterate alphas range and batch computation for speed, memory efficiency, and scaling to larger m_steps.\n",
        "  for alpha in tf.range(0, len(alphas), batch_size):\n",
        "    from_ = alpha\n",
        "    to = tf.minimum(from_ + batch_size, len(alphas))\n",
        "    alpha_batch = alphas[from_:to]\n",
        "\n",
        "    gradient_batch = one_batch(baseline, image, alpha_batch, target_class_idx)\n",
        "    gradient_batches.append(gradient_batch)\n",
        "      \n",
        "  # Concatenate path gradients together row-wise into single tensor.\n",
        "  total_gradients = tf.concat(gradient_batches, axis=0)\n",
        "\n",
        "  # Integral approximation through averaging gradients.\n",
        "  avg_gradients = integral_approximation(gradients=total_gradients)\n",
        "\n",
        "  # Scale integrated gradients with respect to input.\n",
        "  integrated_gradients = (image - baseline) * avg_gradients\n",
        "\n",
        "  return integrated_gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dszwB_Sp0CX0"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def one_batch(baseline, image, alpha_batch, target_class_idx):\n",
        "    # Generate interpolated inputs between baseline and input.\n",
        "    interpolated_path_input_batch = interpolate_images(baseline=baseline,\n",
        "                                                       image=image,\n",
        "                                                       alphas=alpha_batch)\n",
        "\n",
        "    # Compute gradients between model outputs and interpolated inputs.\n",
        "    gradient_batch = compute_gradients(images=interpolated_path_input_batch,\n",
        "                                       target_class_idx=target_class_idx)\n",
        "    return gradient_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8G0ELl_wRrd0"
      },
      "outputs": [],
      "source": [
        "ig_attributions = integrated_gradients(baseline=baseline,\n",
        "                                       image=img_name_tensors['Fireboat'],\n",
        "                                       target_class_idx=555,\n",
        "                                       m_steps=240)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-LSHD2sajFf"
      },
      "source": [
        "Una vez más, puede controlar que las atribuciones de las características de los gradientes integrados tienen la misma forma que la imagen de entrada del \"barco contraincendios\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beoEunC5aZOa"
      },
      "outputs": [],
      "source": [
        "print(ig_attributions.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLaB21txJhMq"
      },
      "source": [
        "El documento sugiere que la cantidad de pasos se encuentra entre 20 y 300 dependiendo del ejemplo (a pesar de que en la práctica, puede ser mayor a 1000 para aproximar la integral con más exactitud). Puede buscar más códigos para controlar la cantidad adecuada de pasos entre los recursos de la sección \"Próximos pasos\" al final de este tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o55W6NYXGSZ8"
      },
      "source": [
        "### Visualización de atribuciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSQ6Y-DZvrQu"
      },
      "source": [
        "Está todo listo para visualizar atribuciones y superponerlas con la imagen original. El código que se encuentra a continuación suma los valores absolutos de los gradientes integrados a través de los canales de colores para producir una máscara de atribución. Este método de trazado captura el impacto relativo de los pixeles en las predicciones del modelo. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QN2cEA_WFym"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "def plot_img_attributions(baseline,\n",
        "                          image,\n",
        "                          target_class_idx,\n",
        "                          m_steps=50,\n",
        "                          cmap=None,\n",
        "                          overlay_alpha=0.4):\n",
        "\n",
        "  attributions = integrated_gradients(baseline=baseline,\n",
        "                                      image=image,\n",
        "                                      target_class_idx=target_class_idx,\n",
        "                                      m_steps=m_steps)\n",
        "\n",
        "  # Sum of the attributions across color channels for visualization.\n",
        "  # The attribution mask shape is a grayscale image with height and width\n",
        "  # equal to the original image.\n",
        "  attribution_mask = tf.reduce_sum(tf.math.abs(attributions), axis=-1)\n",
        "\n",
        "  fig, axs = plt.subplots(nrows=2, ncols=2, squeeze=False, figsize=(8, 8))\n",
        "\n",
        "  axs[0, 0].set_title('Baseline image')\n",
        "  axs[0, 0].imshow(baseline)\n",
        "  axs[0, 0].axis('off')\n",
        "\n",
        "  axs[0, 1].set_title('Original image')\n",
        "  axs[0, 1].imshow(image)\n",
        "  axs[0, 1].axis('off')\n",
        "\n",
        "  axs[1, 0].set_title('Attribution mask')\n",
        "  axs[1, 0].imshow(attribution_mask, cmap=cmap)\n",
        "  axs[1, 0].axis('off')\n",
        "\n",
        "  axs[1, 1].set_title('Overlay')\n",
        "  axs[1, 1].imshow(attribution_mask, cmap=cmap)\n",
        "  axs[1, 1].imshow(image, alpha=overlay_alpha)\n",
        "  axs[1, 1].axis('off')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n73VxzbxeMvD"
      },
      "source": [
        "Si mira las atribuciones en la imagen del \"barco contraincendios\", podrá observar que el modelo identifica que los cañones hidrantes y los chorros contribuyen a la correcta predicción."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxCQFx96iDVs"
      },
      "outputs": [],
      "source": [
        "_ = plot_img_attributions(image=img_name_tensors['Fireboat'],\n",
        "                          baseline=baseline,\n",
        "                          target_class_idx=555,\n",
        "                          m_steps=240,\n",
        "                          cmap=plt.cm.inferno,\n",
        "                          overlay_alpha=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo4SncDZfTw0"
      },
      "source": [
        "En la imagen del \"panda gigante\", las atribuciones destacan la textura, el hocico y el pelo de la cara del panda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcpGLJWuHnYl"
      },
      "outputs": [],
      "source": [
        "_ = plot_img_attributions(image=img_name_tensors['Giant Panda'],\n",
        "                          baseline=baseline,\n",
        "                          target_class_idx=389,\n",
        "                          m_steps=55,\n",
        "                          cmap=plt.cm.viridis,\n",
        "                          overlay_alpha=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3etJZHuI6hX"
      },
      "source": [
        "## Usos y limitaciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEX4Jh2uLvxA"
      },
      "source": [
        "Casos de uso\n",
        "\n",
        "- Emplear técnicas como las de los gradientes integrados antes de implementar su modelo lo ayudará a desarrollar la intuición sobre cómo y por qué funciona. ¿Los atributos destacados por esta técnica coinciden con su intuición? De no ser así, puede ser indicador de que hay un error en su modelo o conjunto de datos, o sobreajuste.\n",
        "\n",
        "Limitaciones\n",
        "\n",
        "- Los gradientes integrados proporcionan la importancia de los atributos en ejemplos individuales; sin embargo, no proveen la importancia de los atributos globales de un conjunto de datos entero.\n",
        "\n",
        "- Los gradientes integrados proporcionan la importancia de los atributos en ejemplos individuales; pero no explican las interacciones ni las combinaciones de los atributos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ejc2Ho_8i162"
      },
      "source": [
        "## Próximos pasos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8Ra5ijj7pEc"
      },
      "source": [
        "En este tutorial se presentó una implementación básica de Gradientes Integrados. En el próximo paso podrá usar estas notas para probar usted mismo esta técnica con diferentes modelos e imágenes.\n",
        "\n",
        "Para los lectores interesados, hay una versión más larga de este tutorial (que incluye código para diferentes bases de referencia, para calcular aproximaciones integrales y para determinar la cantidad suficiente de pasos) que puede encontrar  [aquí](https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/blogs/integrated_gradients).\n",
        "\n",
        "Para profundizar su comprensión, revise la publicación [Axiomatic Attribution for Deep Networks](https://arxiv.org/abs/1703.01365) (Atribución axiomática para redes profundas) y el [repositorio de Github](https://github.com/ankurtaly/Integrated-Gradients), que contiene una implementación con una versión anterior de TensorFlow. También puede explorar la atribución de características y el impacto de diferentes líneas de base en [distill.pub](https://distill.pub/2020/attribution-baselines/).\n",
        "\n",
        "¿Le interesa incorporar los gradientes integrados a la producción de los flujos de aprendizaje automático para determinar la importancia de los atributos, el análisis de errores del modelo y el monitoreo de asimetría estadística (data skew)? Consulte el producto [Explainable AI](https://cloud.google.com/explainable-ai) de Google Cloud que es compatible con las atribuciones de los gradientes integrados. El grupo de investigaciones PAIR de inteligencia artificial de Google también compartió en código abierto la herramienta [What-if tool](https://pair-code.github.io/what-if-tool/index.html#about) que se puede usar para la depuración de modelos, incluida la visualización de las atribuciones de las características de gradientes integrados."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "integrated_gradients.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
